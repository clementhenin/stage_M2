{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data from sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequality measures Deininger and Squire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure whether the good quality criteria in Forbes deals with the variable Quality or Q. In order to be confident of our data, we impose the two conditions. \n",
    "This leads us to 679 points which is very close to the 682 points of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add 6.6 we the data is based on expenditure and not on income (on the same cell to be sure that it is not done twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 679 entries, 0 to 2631\n",
      "Data columns (total 3 columns):\n",
      "Code    679 non-null object\n",
      "Year    679 non-null int64\n",
      "Gini    679 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "DS = pd.read_excel(\"Deininger_and Squire.XLS\", usecols=[\"Code\", \"Quality\", \"Year\", \"Gini\", \"Q\", 'Inc'])\n",
    "DS = DS.query(\"Q == 'good' and Quality == 'accept'\")\n",
    "DS.drop_duplicates([\"Code\", \"Year\"], inplace=True)\n",
    "DS['Gini'].astype(float, inplace=True)\n",
    "\n",
    "DS.loc[DS['Inc']=='E', 'Gini'] += 6.6\n",
    "\n",
    "DS = DS[[\"Code\", \"Year\", \"Gini\"]]\n",
    "DS.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Educational data : Barro-Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the data directly from the BarroLee website. Cf list of name variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male_educ = pd.read_csv(\"male_attainment_25_BarroLee.csv\", usecols=[\"year\", \"WBcode\", \"yr_sch_sec\"])\n",
    "female_educ = pd.read_csv(\"female_attainment_25_BarroLee.csv\", usecols=[\"year\", \"WBcode\", \"yr_sch_sec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1898 entries, 0 to 1897\n",
      "Data columns (total 3 columns):\n",
      "year          1898 non-null int64\n",
      "yr_sch_sec    1898 non-null float64\n",
      "WBcode        1898 non-null object\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 59.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1898 entries, 0 to 1897\n",
      "Data columns (total 3 columns):\n",
      "year          1898 non-null int64\n",
      "yr_sch_sec    1898 non-null float64\n",
      "WBcode        1898 non-null object\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 59.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print male_educ.info()\n",
    "print female_educ.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the data from data.worldbank. The name of the variable has changed from GNP to GNI we should investigate to decide whether or not the differences are big. \n",
    "We secretly hope that the data before 1995 hasn't been changed and consequently that the new name of the variable affects nothing for our study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/index.py:1759: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  return self._engine.get_loc(key)\n"
     ]
    }
   ],
   "source": [
    "inc = pd.read_excel(\"pwt56_forweb.xls\", usecols=[\"Country\", \"Year\", \"RGDPCH\"]).dropna(subset=[\"RGDPCH\"])\n",
    "country_dict = pd.read_csv(\"../data_source/country_code_list.csv\")\n",
    "\n",
    "country_dict.loc[:, 'country'] = country_dict['country'].apply(lambda x: x.upper())\n",
    "country_dict.set_index('country', inplace=True)\n",
    "\n",
    "inc.replace(\"CAPE VERDE IS.\", \"CABO VERDE\", inplace=True)\n",
    "inc.replace(\"CENTRAL AFR.R.\", \"CENTRAL AFRICAN REPUBLIC\", inplace=True)\n",
    "inc.replace(\"GUINEA-BISS\", \"GUINEA-BISSAU\", inplace=True)\n",
    "\n",
    "inc = inc.query(\"Country != 'REUNION'\")\n",
    "\n",
    "inc = inc.query(\"Country != 'ZAIRE'\")\n",
    "\n",
    "inc.replace(\"DOMINICAN REP.\", \"DOMINICAN REPUBLIC\", inplace=True)\n",
    "inc.replace(\"ST.KITTS&NEVIS\", \"SAINT KITTS AND NEVIS\", inplace=True)\n",
    "inc.replace(\"ST.LUCIA\", \"SAINT LUCIA\", inplace=True)\n",
    "inc.replace(\"TRINIDAD&TOBAGO\", \"TRINIDAD AND TOBAGO\", inplace=True)\n",
    "inc.replace(\"U.S.A.\", \"UNITED STATES OF AMERICA\", inplace=True)\n",
    "inc.replace(\"KOREA, REP.\", \"SOUTH KOREA\", inplace=True)\n",
    "inc.replace(\"SYRIA\", \"SYRIAN ARAB REPUBLIC\", inplace=True)\n",
    "inc.replace(\"UNITED ARAB E.\", \"UNITED ARAB EMIRATES\", inplace=True)\n",
    "inc.replace(\"YEMEN\", \"REPUBLIC OF YEMEN\", inplace=True)\n",
    "\n",
    "inc = inc.query(\"Country != 'GERMANY, EAST'\")\n",
    "\n",
    "inc.replace(\"GERMANY, WEST\", \"GERMANY\", inplace=True)\n",
    "inc.replace(\"U.K.\", \"UNITED KINGDOM\", inplace=True)\n",
    "inc.replace(\"U.S.S.R.\", \"RUSSIAN FEDERATION\", inplace=True)\n",
    "inc.replace(\"PAPUA N.GUINEA\", \"PAPUA NEW GUINEA\", inplace=True)\n",
    "inc.replace(\"SOLOMON IS.\", \"SOLOMON ISLANDS\", inplace=True)\n",
    "inc.replace(\"ST.VINCENT&GRE\", \"SAINT VINCENT AND THE GRENADINES\", inplace=True)\n",
    "inc.replace(\"WESTERN SAMOA\", \"SAMOA\", inplace=True)\n",
    "\n",
    "inc['code'] = inc['Country'].apply(lambda x: country_dict.loc[x])\n",
    "inc.columns = [\"Country\", \"year\", \"GDP_PC\", \"code\"]\n",
    "inc = inc[['code', 'year', 'GDP_PC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inc = pd.read_csv(\"GDP_PC_WB.csv\", skiprows=4)\n",
    "#del inc[\"Country Name\"], inc['Indicator Code'], inc['Indicator Name']\n",
    "#inc.set_index(\"Country Code\", inplace=True)\n",
    "#inc = inc.stack().reset_index()\n",
    "#inc.columns = [\"code\", \"year\", \"GNI_PC\"]\n",
    "#print inc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Level of Investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted from the Penn World Table 5.6 (as in Forbes). The name of the variable is PI (cf. documentation column number [15]). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert the Country name to the corresponding code using our good old dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PPPI = pd.read_excel(\"pwt56_forweb.xls\", usecols=[\"Country\", \"Year\", \"PI\"]).dropna(subset=[\"PI\"])\n",
    "country_dict = pd.read_csv(\"../data_source/country_code_list.csv\")\n",
    "\n",
    "country_dict.loc[:, 'country'] = country_dict['country'].apply(lambda x: x.upper())\n",
    "country_dict.set_index('country', inplace=True)\n",
    "\n",
    "PPPI.replace(\"CAPE VERDE IS.\", \"CABO VERDE\", inplace=True)\n",
    "PPPI.replace(\"CENTRAL AFR.R.\", \"CENTRAL AFRICAN REPUBLIC\", inplace=True)\n",
    "PPPI.replace(\"GUINEA-BISS\", \"GUINEA-BISSAU\", inplace=True)\n",
    "\n",
    "PPPI = PPPI.query(\"Country != 'REUNION'\")\n",
    "\n",
    "PPPI = PPPI.query(\"Country != 'ZAIRE'\")\n",
    "\n",
    "PPPI.replace(\"DOMINICAN REP.\", \"DOMINICAN REPUBLIC\", inplace=True)\n",
    "PPPI.replace(\"ST.KITTS&NEVIS\", \"SAINT KITTS AND NEVIS\", inplace=True)\n",
    "PPPI.replace(\"ST.LUCIA\", \"SAINT LUCIA\", inplace=True)\n",
    "PPPI.replace(\"TRINIDAD&TOBAGO\", \"TRINIDAD AND TOBAGO\", inplace=True)\n",
    "PPPI.replace(\"U.S.A.\", \"UNITED STATES OF AMERICA\", inplace=True)\n",
    "PPPI.replace(\"KOREA, REP.\", \"SOUTH KOREA\", inplace=True)\n",
    "PPPI.replace(\"SYRIA\", \"SYRIAN ARAB REPUBLIC\", inplace=True)\n",
    "PPPI.replace(\"UNITED ARAB E.\", \"UNITED ARAB EMIRATES\", inplace=True)\n",
    "PPPI.replace(\"YEMEN\", \"REPUBLIC OF YEMEN\", inplace=True)\n",
    "\n",
    "PPPI = PPPI.query(\"Country != 'GERMANY, EAST'\")\n",
    "\n",
    "PPPI.replace(\"GERMANY, WEST\", \"GERMANY\", inplace=True)\n",
    "PPPI.replace(\"U.K.\", \"UNITED KINGDOM\", inplace=True)\n",
    "PPPI.replace(\"U.S.S.R.\", \"RUSSIAN FEDERATION\", inplace=True)\n",
    "PPPI.replace(\"PAPUA N.GUINEA\", \"PAPUA NEW GUINEA\", inplace=True)\n",
    "PPPI.replace(\"SOLOMON IS.\", \"SOLOMON ISLANDS\", inplace=True)\n",
    "PPPI.replace(\"ST.VINCENT&GRE\", \"SAINT VINCENT AND THE GRENADINES\", inplace=True)\n",
    "PPPI.replace(\"WESTERN SAMOA\", \"SAMOA\", inplace=True)\n",
    "\n",
    "\n",
    "PPPI['code'] = PPPI['Country'].apply(lambda x: country_dict.loc[x])\n",
    "PPPI = PPPI[['code', 'Year', 'PI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4950 entries, 10 to 6533\n",
      "Data columns (total 3 columns):\n",
      "code    4950 non-null object\n",
      "Year    4950 non-null int64\n",
      "PI      4950 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 154.7+ KB\n"
     ]
    }
   ],
   "source": [
    "PPPI.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the data in one frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove rename the columns in preparation of the merging of the databases. \n",
    "We also remove all the duplicates in order to avoid the problems during the merging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates and normalize the data from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income duplicates : 0\n",
      "Inequality duplicates : 0\n",
      "PPPI duplicates : 0\n",
      "Male educ duplicates : 0\n",
      "Female Educ duplicates : 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'GNI_PC'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-535acd7d1448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0minc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0minc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'code'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0minc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GNI_PC'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GNI_PC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1967\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1968\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1969\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1971\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1974\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3211\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GNI_PC'"
     ]
    }
   ],
   "source": [
    "# rename the columns (in order to merge)\n",
    "DS.columns = [\"code\", \"year\", \"gini\"]\n",
    "PPPI.columns = [\"code\", \"year\", \"PPPI\"]\n",
    "male_educ.columns = [\"year\", \"sch_male\", \"code\"]\n",
    "female_educ.columns = [\"year\", \"sch_female\", \"code\"]\n",
    "\n",
    "# drop duplicates in order to avoid problems during the merging\n",
    "print \"Income duplicates :\", inc.duplicated(subset=['code', 'year']).sum()\n",
    "print \"Inequality duplicates :\", DS.duplicated(subset=['code', 'year']).sum()\n",
    "print \"PPPI duplicates :\", PPPI.duplicated(subset=['code', 'year']).sum()\n",
    "print \"Male educ duplicates :\", male_educ.duplicated(subset=['code', 'year']).sum()\n",
    "print \"Female Educ duplicates :\", female_educ.duplicated(subset=['code', 'year']).sum()\n",
    "\n",
    "# normalize the data types\n",
    "DS.loc[:, 'year'] = DS['year'].astype(int)\n",
    "DS.loc[:, 'code'] = DS['code'].astype(str)\n",
    "DS.loc[:, 'gini'] = DS['gini'].astype(float)\n",
    "\n",
    "PPPI.loc[:, 'year'] = PPPI['year'].astype(int)\n",
    "PPPI.loc[:, 'code'] = PPPI['code'].astype(str)\n",
    "PPPI.loc[:, 'PPPI'] = PPPI['PPPI'].astype(float)\n",
    "\n",
    "male_educ.loc[:, 'year'] = male_educ['year'].astype(int)\n",
    "male_educ.loc[:, 'code'] = male_educ['code'].astype(str)\n",
    "male_educ.loc[:, 'sch_male'] = male_educ['sch_male'].astype(float)\n",
    "\n",
    "female_educ.loc[:, 'year'] = female_educ['year'].astype(int)\n",
    "female_educ.loc[:, 'code'] = female_educ['code'].astype(str)\n",
    "female_educ.loc[:, 'sch_female'] = female_educ['sch_female'].astype(float)\n",
    "\n",
    "inc.loc[:, 'year'] = inc['year'].astype(int)\n",
    "inc.loc[:, 'code'] = inc['code'].astype(str)\n",
    "# inc.loc[:, 'GNI_PC'] = inc['GNI_PC'].astype(float)\n",
    "inc.loc[:, 'GDP_PC'] = inc['GDP_PC'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to make sure of the concordance country codes between bases..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some problematic codes in the income database : codes that do not appear in our good old country code dictionary. We see that the corresponding countries are not countries or negligeable countries so we can just drop them from the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problematic_codes = list(set(inc.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_csv(\"GNI_per_capita_WB.csv\", skiprows=4, usecols=['Country Name', 'Country Code'])\n",
    "print country_code[country_code['Country Code'].apply(lambda x: x in problematic_codes)]\n",
    "inc = inc.query(\"code in \" + str(country_dict['code'].values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Dieninger and Squire some codes are not used anymore in the new nomenclature so we choose to change them to the new nomenclature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problematic_codes = list(set(DS.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_excel(\"Deininger_and Squire.XLS\", usecols=[\"Code\", \"Country\"])\n",
    "print country_code[country_code['Code'].apply(lambda x: x in problematic_codes)].drop_duplicates()\n",
    "\n",
    "DS.replace(\"BRS\", \"BLR\", inplace=True)\n",
    "DS.replace(\"CSR\", \"CZE\", inplace=True)\n",
    "DS.replace(\"KYR\", \"KGZ\", inplace=True)\n",
    "DS.replace(\"LAT\", \"LVA\", inplace=True)\n",
    "DS.replace(\"LIT\", \"LTU\", inplace=True)\n",
    "DS.replace(\"MLD\", \"MDA\", inplace=True)\n",
    "DS.replace(\"ROM\", \"ROU\", inplace=True)\n",
    "DS.replace(\"SLO\", \"SVK\", inplace=True)\n",
    "DS.replace(\"SVA\", \"SVN\", inplace=True)\n",
    "DS.replace(\"SUN\", \"RUS\", inplace=True)\n",
    "DS.replace(\"OAN\", \"TWN\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the educationnal data from Barro and Lee some codes are not used anymore in the new nomenclature so we choose to change them to the new nomenclature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problematic_codes = list(set(male_educ.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_csv(\"male_attainment_25_BarroLee.csv\", usecols=[\"WBcode\", \"country\"])\n",
    "print country_code[country_code['WBcode'].apply(lambda x: x in problematic_codes)].drop_duplicates()\n",
    "\n",
    "male_educ.replace(\"ROM\", \"MDA\", inplace=True)\n",
    "male_educ.replace(\"SER\", \"SRB\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problematic_codes = list(set(female_educ.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_csv(\"female_attainment_25_BarroLee.csv\", usecols=[\"WBcode\", \"country\"])\n",
    "print country_code[country_code['WBcode'].apply(lambda x: x in problematic_codes)].drop_duplicates()\n",
    "\n",
    "male_educ.replace(\"ROM\", \"MDA\", inplace=True)\n",
    "male_educ.replace(\"SER\", \"SRB\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frame = pd.merge(DS, PPPI, on=['code', 'year'],how='outer')\n",
    "data_frame = pd.merge(data_frame, male_educ, on=['code', 'year'], how='outer')\n",
    "data_frame = pd.merge(data_frame, female_educ, on=['code', 'year'], how='outer')\n",
    "data_frame = pd.merge(data_frame, inc, on=['code', 'year'], how='outer')\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the log of the GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame[\"log(GNI_PC)\"] = data_frame['GNI_PC'].apply(np.log)\n",
    "del data_frame['GNI_PC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complicated task because it is done in a complex way in the paper. This particular point could be critized btw. \n",
    "One has to read the paper carefully to obtain information on how the resampling is done (note 8). The author choose not to use the mean of all values in the period but only the first values which is not the good way to do in my opinion but here we just redo the calculations. Because the data on inequality is sparse, she allows the values to be not only the first one but the closest from the first one in the considered period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame.reset_index(inplace=True)\n",
    "period = float(5)\n",
    "tuples = zip(data_frame['code'],\n",
    "             (((data_frame['year'].values - 1) // period) * period))\n",
    "df_copy = data_frame.copy()\n",
    "df_copy.index = pd.MultiIndex.from_tuples(tuples)\n",
    "df_copy = df_copy.groupby(level=[0, 1]).last().dropna(how='all')\n",
    "df_copy.index.names = ['code', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame = df_copy\n",
    "del df_copy\n",
    "data_frame = data_frame[['gini', 'PPPI', 'sch_male', 'sch_female', 'log(GNI_PC)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame.loc['CAN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the growth column (of income and Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame.reset_index(inplace=True)\n",
    "data_frame.sort_values(['code', 'year'], inplace=True)\n",
    "data_frame.set_index(['code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_frame = pd.DataFrame()\n",
    "for country in set(data_frame.index.values):\n",
    "    sel = data_frame.loc[country]\n",
    "    if sel.shape != (6,):\n",
    "        sel['growth'] = (sel.shift(-1)['log(GNI_PC)'] - sel['log(GNI_PC)']) / (sel.shift(-1)['year'] - sel['year'])\n",
    "        # sel['gini_growth'] = (sel['gini'] - sel.shift(1)['gini']) / (sel.shift(-1)['year'] - sel['year'])\n",
    "        new_frame = pd.concat([new_frame, sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_frame.loc['CAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame = new_frame.query(\"1985 >= year >= 1960\").dropna(how='any')\n",
    "del new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing countries that doesn't have at least 2 consecutives observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_frame = pd.DataFrame()\n",
    "data_frame.reset_index(inplace=True)\n",
    "for country in set(data_frame['code']):\n",
    "    if len(data_frame.query(\"code == '\" + str(country) + \"'\")) > 1:\n",
    "        sel = data_frame.query(\"code == '\" + str(country) + \"'\")\n",
    "        sel = sel.loc[((sel.shift(-1).year - sel.year) == 5) | ((sel.year - sel.shift(1).year) == 5)]\n",
    "        new_frame = pd.concat([new_frame, sel])\n",
    "data_frame = new_frame\n",
    "del new_frame\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame.sort_values(['code', 'year']).to_csv(\"forbes_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with the data presented in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('precision', 3)\n",
    "nb_per = len(set(data_frame.year))\n",
    "resume = pd.DataFrame()\n",
    "resume = pd.concat([resume, data_frame.groupby('year').mean()])\n",
    "resume = pd.concat([resume, data_frame.groupby('year').std()])\n",
    "resume = pd.concat([resume, data_frame.groupby('year').min()])\n",
    "resume = pd.concat([resume, data_frame.groupby('year').max()])\n",
    "del resume['code']\n",
    "resume['categorize'] = (['mean'] * nb_per + ['std'] * nb_per + ['min'] * nb_per + ['max'] * nb_per) \n",
    "result = resume.reset_index().set_index(['categorize', 'year']).stack(level=0).unstack(level=0).swaplevel(0,1).sort_index()\n",
    "print result[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print data_frame[['code', 'year', 'gini']].set_index(['code', 'year']).unstack(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
