{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data from sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequality measures Deininger and Squire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure whether the good quality criteria in Forbes deals with the variable Quality or Q. In order to be confident of our data, we impose the two conditions. \n",
    "This leads us to 679 points which is very close to the 682 points of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add 6.6 we the data is based on expenditure and not on income (on the same cell to be sure that it is not done twice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 679 entries, 0 to 2631\n",
      "Data columns (total 3 columns):\n",
      "Code    679 non-null object\n",
      "Year    679 non-null int64\n",
      "Gini    679 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "DS = pd.read_excel(\"Deininger_and Squire.XLS\", usecols=[\"Code\", \"Quality\", \"Year\", \"Gini\", \"Q\", 'Inc'])\n",
    "DS = DS.query(\"Q == 'good' and Quality == 'accept'\")\n",
    "DS.drop_duplicates([\"Code\", \"Year\"], inplace=True)\n",
    "DS['Gini'].astype(float, inplace=True)\n",
    "\n",
    "DS.loc[DS['Inc']=='E', 'Gini'] += 6.6\n",
    "\n",
    "DS = DS[[\"Code\", \"Year\", \"Gini\"]]\n",
    "DS.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Educational data : Barro-Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the data directly from the BarroLee website. Cf list of name variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "male_educ = pd.read_csv(\"male_attainment_25_BarroLee.csv\", usecols=[\"year\", \"WBcode\", \"yr_sch_sec\"])\n",
    "female_educ = pd.read_csv(\"female_attainment_25_BarroLee.csv\", usecols=[\"year\", \"WBcode\", \"yr_sch_sec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1898 entries, 0 to 1897\n",
      "Data columns (total 3 columns):\n",
      "year          1898 non-null int64\n",
      "yr_sch_sec    1898 non-null float64\n",
      "WBcode        1898 non-null object\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 59.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1898 entries, 0 to 1897\n",
      "Data columns (total 3 columns):\n",
      "year          1898 non-null int64\n",
      "yr_sch_sec    1898 non-null float64\n",
      "WBcode        1898 non-null object\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 59.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print male_educ.info()\n",
    "print female_educ.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the data from data.worldbank. The name of the variable has changed from GNP to GNI we should investigate to decide whether or not the differences are big. \n",
    "We secretly hope that the data before 1995 hasn't been changed and consequently that the new name of the variable affects nothing for our study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9131 entries, 0 to 9130\n",
      "Data columns (total 3 columns):\n",
      "code      9131 non-null object\n",
      "year      9131 non-null object\n",
      "GNI_PC    9131 non-null float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 285.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inc = pd.read_csv(\"GNI_per_capita_WB.csv\", skiprows=4)\n",
    "del inc[\"Country Name\"], inc['Indicator Code'], inc['Indicator Name']\n",
    "inc.set_index(\"Country Code\", inplace=True)\n",
    "inc = inc.stack().reset_index()\n",
    "inc.columns = [\"code\", \"year\", \"GNI_PC\"]\n",
    "print inc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Level of Investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted from the Penn World Table 5.6 (as in Forbes). The name of the variable is PI (cf. documentation column number [15]). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert the Country name to the corresponding code using our good old dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PPPI = pd.read_excel(\"pwt56_forweb.xls\", usecols=[\"Country\", \"Year\", \"PI\"]).dropna(subset=[\"PI\"])\n",
    "country_dict = pd.read_csv(\"../data_source/country_code_list.csv\")\n",
    "\n",
    "country_dict.loc[:, 'country'] = country_dict['country'].apply(lambda x: x.upper())\n",
    "country_dict.set_index('country', inplace=True)\n",
    "\n",
    "PPPI.replace(\"CAPE VERDE IS.\", \"CABO VERDE\", inplace=True)\n",
    "PPPI.replace(\"CENTRAL AFR.R.\", \"CENTRAL AFRICAN REPUBLIC\", inplace=True)\n",
    "PPPI.replace(\"GUINEA-BISS\", \"GUINEA-BISSAU\", inplace=True)\n",
    "\n",
    "PPPI = PPPI.query(\"Country != 'REUNION'\")\n",
    "\n",
    "PPPI = PPPI.query(\"Country != 'ZAIRE'\")\n",
    "\n",
    "PPPI.replace(\"DOMINICAN REP.\", \"DOMINICAN REPUBLIC\", inplace=True)\n",
    "PPPI.replace(\"ST.KITTS&NEVIS\", \"SAINT KITTS AND NEVIS\", inplace=True)\n",
    "PPPI.replace(\"ST.LUCIA\", \"SAINT LUCIA\", inplace=True)\n",
    "PPPI.replace(\"TRINIDAD&TOBAGO\", \"TRINIDAD AND TOBAGO\", inplace=True)\n",
    "PPPI.replace(\"U.S.A.\", \"UNITED STATES OF AMERICA\", inplace=True)\n",
    "PPPI.replace(\"KOREA, REP.\", \"SOUTH KOREA\", inplace=True)\n",
    "PPPI.replace(\"SYRIA\", \"SYRIAN ARAB REPUBLIC\", inplace=True)\n",
    "PPPI.replace(\"UNITED ARAB E.\", \"UNITED ARAB EMIRATES\", inplace=True)\n",
    "PPPI.replace(\"YEMEN\", \"REPUBLIC OF YEMEN\", inplace=True)\n",
    "\n",
    "PPPI = PPPI.query(\"Country != 'GERMANY, EAST'\")\n",
    "\n",
    "PPPI.replace(\"GERMANY, WEST\", \"GERMANY\", inplace=True)\n",
    "PPPI.replace(\"U.K.\", \"UNITED KINGDOM\", inplace=True)\n",
    "PPPI.replace(\"U.S.S.R.\", \"RUSSIAN FEDERATION\", inplace=True)\n",
    "PPPI.replace(\"PAPUA N.GUINEA\", \"PAPUA NEW GUINEA\", inplace=True)\n",
    "PPPI.replace(\"SOLOMON IS.\", \"SOLOMON ISLANDS\", inplace=True)\n",
    "PPPI.replace(\"ST.VINCENT&GRE\", \"SAINT VINCENT AND THE GRENADINES\", inplace=True)\n",
    "PPPI.replace(\"WESTERN SAMOA\", \"SAMOA\", inplace=True)\n",
    "\n",
    "\n",
    "PPPI['code'] = PPPI['Country'].apply(lambda x: country_dict.loc[x])\n",
    "PPPI = PPPI[['code', 'Year', 'PI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4950 entries, 10 to 6533\n",
      "Data columns (total 3 columns):\n",
      "code    4950 non-null object\n",
      "Year    4950 non-null int64\n",
      "PI      4950 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 154.7+ KB\n"
     ]
    }
   ],
   "source": [
    "PPPI.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the data in one frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove rename the columns in preparation of the merging of the databases. \n",
    "We also remove all the duplicates in order to avoid the problems during the merging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates and normalize the data from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income duplicates : 0\n",
      "Inequality duplicates : 0\n",
      "PPPI duplicates : 0\n",
      "Male educ duplicates : 0\n",
      "Female Educ duplicates : 0\n"
     ]
    }
   ],
   "source": [
    "# rename the columns (in order to merge)\n",
    "DS.columns = [\"code\", \"year\", \"gini\"]\n",
    "PPPI.columns = [\"code\", \"year\", \"PPPI\"]\n",
    "male_educ.columns = [\"year\", \"sch_male\", \"code\"]\n",
    "female_educ.columns = [\"year\", \"sch_female\", \"code\"]\n",
    "\n",
    "# drop duplicates in order to avoid problems during the merging\n",
    "print \"Income duplicates :\", inc.duplicated(subset=['code', 'year']).sum()\n",
    "print \"Inequality duplicates :\", DS.duplicated(subset=['code', 'year']).sum()\n",
    "print \"PPPI duplicates :\", PPPI.duplicated(subset=['code', 'year']).sum()\n",
    "print \"Male educ duplicates :\", male_educ.duplicated(subset=['code', 'year']).sum()\n",
    "print \"Female Educ duplicates :\", female_educ.duplicated(subset=['code', 'year']).sum()\n",
    "\n",
    "# normalize the data types\n",
    "DS.loc[:, 'year'] = DS['year'].astype(int)\n",
    "DS.loc[:, 'code'] = DS['code'].astype(str)\n",
    "DS.loc[:, 'gini'] = DS['gini'].astype(float)\n",
    "\n",
    "PPPI.loc[:, 'year'] = PPPI['year'].astype(int)\n",
    "PPPI.loc[:, 'code'] = PPPI['code'].astype(str)\n",
    "PPPI.loc[:, 'PPPI'] = PPPI['PPPI'].astype(float)\n",
    "\n",
    "male_educ.loc[:, 'year'] = male_educ['year'].astype(int)\n",
    "male_educ.loc[:, 'code'] = male_educ['code'].astype(str)\n",
    "male_educ.loc[:, 'sch_male'] = male_educ['sch_male'].astype(float)\n",
    "\n",
    "female_educ.loc[:, 'year'] = female_educ['year'].astype(int)\n",
    "female_educ.loc[:, 'code'] = female_educ['code'].astype(str)\n",
    "female_educ.loc[:, 'sch_female'] = female_educ['sch_female'].astype(float)\n",
    "\n",
    "inc.loc[:, 'year'] = inc['year'].astype(int)\n",
    "inc.loc[:, 'code'] = inc['code'].astype(str)\n",
    "inc.loc[:, 'GNI_PC'] = inc['GNI_PC'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to make sure of the concordance country codes between bases..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some problematic codes in the income database : codes that do not appear in our good old country code dictionary. We see that the corresponding countries are not countries or negligeable countries so we can just drop them from the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Country Name Country Code\n",
      "5                                        Arab World          ARB\n",
      "34                   Central Europe and the Baltics          CEB\n",
      "36                                  Channel Islands          CHI\n",
      "46                           Caribbean small states          CSS\n",
      "58            East Asia & Pacific (developing only)          EAP\n",
      "59          East Asia & Pacific (all income levels)          EAS\n",
      "60          Europe & Central Asia (developing only)          ECA\n",
      "61        Europe & Central Asia (all income levels)          ECS\n",
      "64                                        Euro area          EMU\n",
      "69                                   European Union          EUU\n",
      "70         Fragile and conflict affected situations          FCS\n",
      "90                                      High income          HIC\n",
      "93           Heavily indebted poor countries (HIPC)          HPC\n",
      "119     Latin America & Caribbean (developing only)          LAC\n",
      "125   Latin America & Caribbean (all income levels)          LCN\n",
      "126    Least developed countries: UN classification          LDC\n",
      "127                                      Low income          LIC\n",
      "130                             Lower middle income          LMC\n",
      "131                             Low & middle income          LMY\n",
      "143  Middle East & North Africa (all income levels)          MEA\n",
      "146                                   Middle income          MIC\n",
      "151    Middle East & North Africa (developing only)          MNA\n",
      "160                                   North America          NAC\n",
      "167                            High income: nonOECD          NOC\n",
      "171                               High income: OECD          OEC\n",
      "172                                    OECD members          OED\n",
      "174                              Other small states          OSS\n",
      "186                     Pacific island small states          PSS\n",
      "192                                      South Asia          SAS\n",
      "203            Sub-Saharan Africa (developing only)          SSA\n",
      "205          Sub-Saharan Africa (all income levels)          SSF\n",
      "206                                    Small states          SST\n",
      "231                             Upper middle income          UMC\n",
      "241                                           World          WLD\n"
     ]
    }
   ],
   "source": [
    "problematic_codes = list(set(inc.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_csv(\"GNI_per_capita_WB.csv\", skiprows=4, usecols=['Country Name', 'Country Code'])\n",
    "print country_code[country_code['Country Code'].apply(lambda x: x in problematic_codes)]\n",
    "inc = inc.query(\"code in \" + str(country_dict['code'].values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Dieninger and Squire some codes are not used anymore in the new nomenclature so we choose to change them to the new nomenclature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country Code\n",
      "162        Belarus  BRS\n",
      "580      Czech Rep  CSR\n",
      "1407   Kyrgyz Rep.  KYR\n",
      "1409        Latvia  LAT\n",
      "1415     Lithuania  LIT\n",
      "1541       Moldova  MLD\n",
      "1914       Romania  ROM\n",
      "1956        Slovak  SLO\n",
      "1957   Slovak Rep.  SLO\n",
      "1966      Slovenia  SVA\n",
      "1981  Soviet Union  SUN\n",
      "2151        Taiwan  OAN\n"
     ]
    }
   ],
   "source": [
    "problematic_codes = list(set(DS.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_excel(\"Deininger_and Squire.XLS\", usecols=[\"Code\", \"Country\"])\n",
    "print country_code[country_code['Code'].apply(lambda x: x in problematic_codes)].drop_duplicates()\n",
    "\n",
    "DS.replace(\"BRS\", \"BLR\", inplace=True)\n",
    "DS.replace(\"CSR\", \"CZE\", inplace=True)\n",
    "DS.replace(\"KYR\", \"KGZ\", inplace=True)\n",
    "DS.replace(\"LAT\", \"LVA\", inplace=True)\n",
    "DS.replace(\"LIT\", \"LTU\", inplace=True)\n",
    "DS.replace(\"MLD\", \"MDA\", inplace=True)\n",
    "DS.replace(\"ROM\", \"ROU\", inplace=True)\n",
    "DS.replace(\"SLO\", \"SVK\", inplace=True)\n",
    "DS.replace(\"SVA\", \"SVN\", inplace=True)\n",
    "DS.replace(\"SUN\", \"RUS\", inplace=True)\n",
    "DS.replace(\"OAN\", \"TWN\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the educationnal data from Barro and Lee some codes are not used anymore in the new nomenclature so we choose to change them to the new nomenclature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  country WBcode\n",
      "1833  Republic of Moldova    ROM\n",
      "1846               Serbia    SER\n"
     ]
    }
   ],
   "source": [
    "problematic_codes = list(set(male_educ.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_csv(\"male_attainment_25_BarroLee.csv\", usecols=[\"WBcode\", \"country\"])\n",
    "print country_code[country_code['WBcode'].apply(lambda x: x in problematic_codes)].drop_duplicates()\n",
    "\n",
    "male_educ.replace(\"ROM\", \"MDA\", inplace=True)\n",
    "male_educ.replace(\"SER\", \"SRB\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  country WBcode\n",
      "1833  Republic of Moldova    ROM\n",
      "1846               Serbia    SER\n"
     ]
    }
   ],
   "source": [
    "problematic_codes = list(set(female_educ.query(\"code not in \" + str(country_dict['code'].values.tolist()))['code']))\n",
    "country_code = pd.read_csv(\"female_attainment_25_BarroLee.csv\", usecols=[\"WBcode\", \"country\"])\n",
    "print country_code[country_code['WBcode'].apply(lambda x: x in problematic_codes)].drop_duplicates()\n",
    "\n",
    "male_educ.replace(\"ROM\", \"MDA\", inplace=True)\n",
    "male_educ.replace(\"SER\", \"SRB\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frame = pd.merge(DS, PPPI, on=['code', 'year'],how='outer')\n",
    "data_frame = pd.merge(data_frame, male_educ, on=['code', 'year'], how='outer')\n",
    "data_frame = pd.merge(data_frame, female_educ, on=['code', 'year'], how='outer')\n",
    "data_frame = pd.merge(data_frame, inc, on=['code', 'year'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the growth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame.sort_values(['code', 'year'], inplace=True)\n",
    "data_frame.set_index(['code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_frame = pd.DataFrame()\n",
    "for country in set(data_frame.index.values):\n",
    "    sel = data_frame.loc[country]\n",
    "    sel['growth'] = (sel.shift(-1)['GNI_PC'] - sel['GNI_PC']) / (sel.shift(-1)['year'] - sel['year'])\n",
    "    new_frame = pd.concat([new_frame, sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10011 entries, AGO to CUB\n",
      "Data columns (total 7 columns):\n",
      "year          10011 non-null float64\n",
      "gini          679 non-null float64\n",
      "PPPI          4950 non-null float64\n",
      "sch_male      1898 non-null float64\n",
      "sch_female    1898 non-null float64\n",
      "GNI_PC        7690 non-null float64\n",
      "growth        7481 non-null float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 625.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_frame = new_frame\n",
    "del new_frame\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the log of the GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame[\"log(GNI_PC)\"] = data_frame['GNI_PC'].apply(np.log)\n",
    "del data_frame['GNI_PC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complicated task because it is done in a complex way in the paper. This particular point could be critized btw. \n",
    "One has to read the paper carefully to obtain information on how the resampling is done (note 8). The author choose not to use the mean of all values in the period but only the first values which is not the good way to do in my opinion but here we just redo the calculations. Because the data on inequality is sparse, she allows the values to be not only the first one but the closest from the first one in the considered period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame.reset_index(inplace=True)\n",
    "period = float(5)\n",
    "tuples = zip(data_frame['code'],\n",
    "             (((data_frame['year'].values) // period) * period))\n",
    "df_copy = data_frame.copy()\n",
    "df_copy.index = pd.MultiIndex.from_tuples(tuples)\n",
    "df_copy = df_copy.groupby(level=[0, 1]).first().dropna(how='all')\n",
    "df_copy.index.names = ['code', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame = df_copy.dropna(how='any')\n",
    "del df_copy\n",
    "data_frame = data_frame[['gini', 'PPPI', 'sch_male', 'sch_female', 'growth', 'log(GNI_PC)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing countries that doesn't have at least 2 consecutives observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_frame = pd.DataFrame()\n",
    "data_frame.reset_index(inplace=True)\n",
    "for country in set(data_frame['code']):\n",
    "    if len(data_frame.query(\"code == '\" + str(country) + \"'\")) > 1:\n",
    "        sel = data_frame.query(\"code == '\" + str(country) + \"'\")\n",
    "        if 0 in (sel.shift(-1).index.values - sel.index.values):\n",
    "            new_frame = pd.concat([new_frame, sel])\n",
    "data_frame = new_frame\n",
    "del new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame.sort_values(['code', 'year']).to_csv(\"forbes_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with the data presented in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorize          mean     std      min      max\n",
      "            year                                  \n",
      "PPPI        1960   78.75   26.06    44.15   123.74\n",
      "            1965   80.60   48.19    31.96   274.03\n",
      "            1970   67.90   18.28    39.96   112.43\n",
      "            1975   94.62   34.32    50.29   253.78\n",
      "            1980   96.09   27.85    44.43   140.68\n",
      "            1985   69.90   39.16    31.79   288.12\n",
      "            1990   80.54   39.30    27.91   218.17\n",
      "gini        1960   42.85    8.26    30.80    55.50\n",
      "            1965   41.86    9.28    31.61    61.88\n",
      "            1970   41.54    8.19    25.10    57.61\n",
      "            1975   40.68    9.18    23.30    60.29\n",
      "            1980   39.41    7.86    24.90    57.78\n",
      "            1985   41.01    9.44    23.42    61.76\n",
      "            1990   40.74    8.82    24.53    56.91\n",
      "growth      1960   39.23   54.69   -30.00   140.00\n",
      "            1965   89.09   93.09     0.00   310.00\n",
      "            1970  160.61  214.46   -20.00  1070.00\n",
      "            1975  282.37  302.12   -30.00  1140.00\n",
      "            1980  213.26  444.23  -910.00  1050.00\n",
      "            1985  519.57  720.25  -190.00  2290.00\n",
      "            1990  290.75  661.91 -1480.00  1700.00\n",
      "log(GNI_PC) 1960    6.03    1.26     4.50     8.10\n",
      "            1965    6.23    1.27     4.38     8.26\n",
      "            1970    6.66    1.11     4.50     8.59\n",
      "            1975    7.45    1.32     5.08     9.23\n",
      "            1980    8.05    1.26     5.39     9.76\n",
      "            1985    7.71    1.32     5.25     9.77\n",
      "            1990    7.94    1.63     5.74    10.23\n",
      "sch_female  1960    0.81    0.97     0.02     3.19\n",
      "            1965    0.84    1.02     0.05     3.79\n",
      "            1970    0.91    0.87     0.04     4.30\n",
      "            1975    1.28    1.18     0.06     4.76\n",
      "            1980    1.55    1.19     0.15     5.11\n",
      "            1985    1.76    1.20     0.10     5.26\n",
      "            1990    1.99    1.30     0.17     5.37\n",
      "sch_male    1960    1.05    0.89     0.16     3.07\n",
      "            1965    1.10    0.97     0.22     3.71\n",
      "            1970    1.24    0.83     0.32     4.26\n",
      "            1975    1.66    1.19     0.28     4.75\n",
      "            1980    1.99    1.15     0.57     5.14\n",
      "            1985    2.18    1.15     0.32     4.88\n",
      "            1990    2.42    1.19     0.53     4.80\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('precision', 2)\n",
    "resume = pd.DataFrame()\n",
    "resume = pd.concat([resume, data_frame.groupby('year').mean()])\n",
    "resume = pd.concat([resume, data_frame.groupby('year').std()])\n",
    "resume = pd.concat([resume, data_frame.groupby('year').min()])\n",
    "resume = pd.concat([resume, data_frame.groupby('year').max()])\n",
    "del resume['code']\n",
    "resume['categorize'] = (['mean'] * 7 + ['std'] * 7 + ['min'] * 7 + ['max'] * 7) \n",
    "result = resume.reset_index().set_index(['categorize', 'year']).stack(level=0).unstack(level=0).swaplevel(0,1).sort_index()\n",
    "print result[['mean', 'std', 'min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gini                                          \n",
      "year   1960   1965   1970   1975   1980   1985   1990\n",
      "code                                                 \n",
      "AUS     NaN  32.02    NaN  34.33  39.96  37.58  41.72\n",
      "BEL     NaN    NaN    NaN  28.25    NaN  26.22  26.92\n",
      "BGD     NaN    NaN  36.00  33.34  39.00  37.00  34.87\n",
      "BGR     NaN    NaN    NaN    NaN  25.01  23.42  24.53\n",
      "BRA   53.00    NaN  57.61  60.29  57.78  61.76    NaN\n",
      "CAN   30.80  31.61  32.24  31.62  31.80  32.81  27.56\n",
      "CHL     NaN  45.64  46.00    NaN  53.21  57.88  56.49\n",
      "CHN     NaN    NaN    NaN    NaN  32.00  31.40  34.60\n",
      "COL     NaN    NaN  52.02  54.50    NaN  51.20  51.32\n",
      "CRI   50.00    NaN  44.40  50.00  47.49  42.00    NaN\n",
      "DEU     NaN    NaN  30.62  32.06  30.59    NaN    NaN\n",
      "DNK     NaN    NaN    NaN  31.00  30.99  33.15  33.20\n",
      "DOM     NaN    NaN    NaN  45.00  43.29    NaN  49.00\n",
      "EGY     NaN  46.60    NaN  44.60    NaN    NaN  38.60\n",
      "ESP     NaN  31.99  37.11    NaN  33.39  31.79    NaN\n",
      "FIN     NaN  31.80  27.00  30.45  30.86  26.19  26.11\n",
      "FRA   49.00  47.00  44.00  43.00  34.91    NaN    NaN\n",
      "GBR     NaN    NaN  25.10  23.30  24.90  27.10  32.30\n",
      "GHA     NaN    NaN    NaN    NaN    NaN  42.50  40.57\n",
      "GRC     NaN    NaN  41.71    NaN  39.89  41.79    NaN\n",
      "GTM     NaN    NaN    NaN  49.72    NaN  58.26    NaN\n",
      "HKG     NaN    NaN  40.90  40.90  37.30  42.00  45.00\n",
      "HND     NaN  61.88    NaN    NaN    NaN  54.94  54.00\n",
      "IDN     NaN  39.30  37.30  41.20  42.21  38.61  39.69\n",
      "IND   39.19  37.74  36.98  38.74  38.09  38.82  36.29\n",
      "IRL     NaN    NaN  38.69    NaN  35.65  34.60    NaN\n",
      "IRN     NaN  48.48  52.05    NaN  49.50    NaN    NaN\n",
      "ITA     NaN    NaN  41.00  39.00  34.29  33.58  32.19\n",
      "JAM     NaN    NaN  47.87  51.12    NaN  49.76  48.39\n",
      "JOR     NaN    NaN    NaN    NaN  47.40  42.70  47.26\n",
      "JPN   37.20  34.80  35.50  34.40  33.40  35.90  35.00\n",
      "KOR   32.00  34.34  33.30  39.10  38.63  34.54    NaN\n",
      "LKA   47.00    NaN  37.71  43.50  42.00  46.70  36.70\n",
      "MAR     NaN    NaN    NaN    NaN  45.79    NaN  45.80\n",
      "MEX   55.50  57.70    NaN  57.90  50.58  54.98  56.91\n",
      "MUS     NaN    NaN    NaN    NaN  45.70  46.23  43.29\n",
      "MYS     NaN    NaN  50.00  53.00  48.00  48.35    NaN\n",
      "NLD     NaN    NaN    NaN  28.60  26.66  29.10  29.38\n",
      "NOR   37.52  36.04  37.48  37.30  30.57  31.39  33.31\n",
      "NZL     NaN    NaN    NaN  30.04  34.79  35.82  40.21\n",
      "PAK     NaN  37.16  36.51  38.92    NaN  39.04  37.75\n",
      "PAN     NaN    NaN  57.00  48.76  47.47  56.47    NaN\n",
      "PER     NaN    NaN    NaN    NaN  49.33  49.36  51.47\n",
      "PHL   49.71  51.32  49.39    NaN    NaN  46.08  45.00\n",
      "PRT     NaN    NaN  40.58    NaN  36.80    NaN  36.76\n",
      "SGP     NaN    NaN  41.00  37.00  40.69  41.00    NaN\n",
      "SWE     NaN  33.41    NaN  27.31  32.44  31.24  32.52\n",
      "THA   41.28  42.63    NaN  41.74  43.10  47.40  48.80\n",
      "TTO     NaN    NaN  51.00  46.09  41.72    NaN    NaN\n",
      "TUN     NaN  48.90    NaN  50.60  49.60  49.60  46.84\n",
      "TUR     NaN  56.00  51.00    NaN    NaN  44.09    NaN\n",
      "UGA     NaN    NaN    NaN    NaN    NaN  39.60  47.38\n",
      "USA   34.88  34.64  34.06  34.42  35.20  37.26  37.80\n",
      "VEN     NaN    NaN  47.65  43.63  42.82  45.17  53.84\n",
      "ZMB     NaN    NaN    NaN  51.00    NaN    NaN  50.11\n"
     ]
    }
   ],
   "source": [
    "print data_frame[['code', 'year', 'gini']].set_index(['code', 'year']).unstack(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
